ARG UBUNTU_VERSION

FROM nvidia/cuda:11.1.1-cudnn8-runtime-ubuntu${UBUNTU_VERSION}

ARG PYTHON_VERSION
ARG APPLY_THALES
ARG MODEL_SERVICE
ARG BASE_PATH
ARG LINUX_ENV_PATH
ARG DEMOMA_PATH
ARG SO_EXTENTION
ARG USER
ARG CUSTOMER
ARG BUNDLE_PATH
ARG BENTOML_PACKAGE_PATH=/usr/local/lib/python${PYTHON_VERSION}/dist-packages/bentoml/frameworks
ARG APP_NAME=inference_server

ENV LC_ALL=C.UTF-8
ENV LANG=C.UTF-8
ENV CUSTOMER=${CUSTOMER}
ENV PYTHONPATH="$PYTHONPATH:/workspace/${APP_NAME}"

RUN apt-get update && \
    apt-get install -y git  && \
    apt-get install wget && \
    apt-get -y install python3-pip && \
    DEBIAN_FRONTEND="noninteractive" apt-get -y install tzdata && \
    apt-get -y install libgl1-mesa-glx libglib2.0-0

RUN apt install -y libprotobuf-dev protobuf-compiler && \
    apt-get -y install cmake

RUN pip3 install --upgrade pip

WORKDIR /workspace

RUN git clone https://github.com/Nuitka/Nuitka.git && \
    cd Nuitka && \
    python3 setup.py install

# for bento dockerization
WORKDIR /bin
RUN wget "http://stedolan.github.io/jq/download/linux64/jq" && \
    chmod 755 jq

RUN pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html

COPY ./requirments/requirments-serving.txt /workspace/requirments-serving.txt
RUN pip3 install -r /workspace/requirments-serving.txt && \
    sed -i 's/task=task.to_json(),/task=InferenceTask(**{key: getattr(task, key) for key in task.__dict__ if key != "data" }),/' /usr/local/lib/python3.6/dist-packages/bentoml/service/inference_api.py

COPY ./${APP_NAME} /workspace/${APP_NAME}
COPY ./assets/* /workspace/assets/
COPY ./lovit/lovit /workspace/${APP_NAME}/lovit
COPY ./assets/thales/ /workspace/assets/thales
COPY ./.env /workspace/.env

WORKDIR /
